apiVersion: template.openshift.io/v1
kind: Template
metadata:
  name: assisted-events-stream-projection
objects:
- apiVersion: apps/v1
  kind: StatefulSet
  metadata:
    labels:
      app.kubernetes.io/instance: assisted-events-streams
      app.kubernetes.io/name: redis
    name: assisted-events-streams-redis
  spec:
    replicas: 1
    selector:
      matchLabels:
        app.kubernetes.io/instance: assisted-events-streams
        app.kubernetes.io/name: redis
    serviceName: assisted-events-streams-redis-headless
    template:
      metadata:
        labels:
          app.kubernetes.io/instance: assisted-events-streams
          app.kubernetes.io/name: redis
      spec:
        affinity:
          podAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: enriched-event-projection
                namespaces:
                - ${NAMESPACE}
                topologyKey: kubernetes.io/hostname
              weight: 1
        containers:
        - args:
          - -c
          - /opt/bitnami/scripts/start-scripts/start-master.sh
          command:
          - /bin/bash
          env:
          - name: BITNAMI_DEBUG
            value: "false"
          - name: REDIS_REPLICATION_MODE
            value: master
          - name: ALLOW_EMPTY_PASSWORD
            value: "no"
          - name: REDIS_PASSWORD
            valueFrom:
              secretKeyRef:
                key: password
                name: ${REDIS_CREDENTIALS_SECRETNAME}
          - name: REDIS_TLS_ENABLED
            value: "no"
          - name: REDIS_PORT
            value: "6379"
          image: ${REDIS_IMAGE_NAME}:${REDIS_IMAGE_TAG}
          imagePullPolicy: IfNotPresent
          livenessProbe:
            exec:
              command:
              - sh
              - -c
              - /health/ping_liveness_local.sh 5
            failureThreshold: 5
            initialDelaySeconds: 20
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 6
          name: redis
          ports:
          - containerPort: 6379
            name: redis
          readinessProbe:
            exec:
              command:
              - sh
              - -c
              - /health/ping_readiness_local.sh 1
            failureThreshold: 5
            initialDelaySeconds: 20
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 2
          resources:
            limits: {}
            requests: {}
          securityContext:
            runAsNonRoot: true
          volumeMounts:
          - mountPath: /opt/bitnami/scripts/start-scripts
            name: start-scripts
          - mountPath: /health
            name: health
          - mountPath: /data
            name: redis-data
            subPath: null
          - mountPath: /opt/bitnami/redis/mounted-etc
            name: config
          - mountPath: /opt/bitnami/redis/etc/
            name: redis-tmp-conf
          - mountPath: /tmp
            name: tmp
        - command:
          - /bin/bash
          - -c
          - |
            if [[ -f '/secrets/redis-password' ]]; then
            export REDIS_PASSWORD=$(cat /secrets/redis-password)
            fi
            redis_exporter
          env:
          - name: REDIS_ALIAS
            value: assisted-events-streams-redis
          - name: REDIS_USER
            value: default
          - name: REDIS_PASSWORD
            valueFrom:
              secretKeyRef:
                key: password
                name: ${REDIS_CREDENTIALS_SECRETNAME}
          image: ${REDIS_EXPORTER_IMAGE_NAME}:${REDIS_EXPORTER_IMAGE_TAG}
          imagePullPolicy: IfNotPresent
          name: metrics
          ports:
          - containerPort: 9121
            name: metrics
          resources:
            limits: {}
            requests: {}
          securityContext:
            runAsNonRoot: true
          volumeMounts: null
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 493
            name: assisted-events-streams-redis-scripts
          name: start-scripts
        - configMap:
            defaultMode: 493
            name: assisted-events-streams-redis-health
          name: health
        - configMap:
            name: assisted-events-streams-redis-configuration
          name: config
        - emptyDir: {}
          name: redis-tmp-conf
        - emptyDir: {}
          name: tmp
    updateStrategy:
      rollingUpdate: {}
      type: RollingUpdate
    volumeClaimTemplates:
    - metadata:
        labels:
          app.kubernetes.io/instance: assisted-events-streams
          app.kubernetes.io/name: redis
        name: redis-data
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: ${REDIS_STORAGE}
- apiVersion: v1
  kind: Service
  metadata:
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: assisted-events-streams
      app.kubernetes.io/name: redis
    name: assisted-events-streams-redis-metrics
  spec:
    ports:
    - name: http-metrics
      port: 9121
      protocol: TCP
      targetPort: metrics
    selector:
      app.kubernetes.io/instance: assisted-events-streams
      app.kubernetes.io/name: redis
    type: ClusterIP
- apiVersion: v1
  kind: Service
  metadata:
    labels:
      app.kubernetes.io/instance: assisted-events-streams
      app.kubernetes.io/name: redis
    name: assisted-events-streams-redis
  spec:
    internalTrafficPolicy: Cluster
    ports:
    - name: tcp-redis
      nodePort: null
      port: 6379
      targetPort: redis
    selector:
      app.kubernetes.io/instance: assisted-events-streams
      app.kubernetes.io/name: redis
    sessionAffinity: None
    type: ClusterIP
- apiVersion: v1
  kind: Service
  metadata:
    labels:
      app.kubernetes.io/instance: assisted-events-streams
      app.kubernetes.io/name: redis
    name: assisted-events-streams-redis-headless
  spec:
    clusterIP: None
    ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
    selector:
      app.kubernetes.io/instance: assisted-events-streams
      app.kubernetes.io/name: redis
    type: ClusterIP
- apiVersion: v1
  data:
    start-master.sh: |
      #!/bin/bash

      [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
      if [[ ! -f /opt/bitnami/redis/etc/master.conf ]];then
          cp /opt/bitnami/redis/mounted-etc/master.conf /opt/bitnami/redis/etc/master.conf
      fi
      if [[ ! -f /opt/bitnami/redis/etc/redis.conf ]];then
          cp /opt/bitnami/redis/mounted-etc/redis.conf /opt/bitnami/redis/etc/redis.conf
      fi
      ARGS=("--port" "${REDIS_PORT}")
      ARGS+=("--requirepass" "${REDIS_PASSWORD}")
      ARGS+=("--masterauth" "${REDIS_PASSWORD}")
      ARGS+=("--include" "/opt/bitnami/redis/etc/redis.conf")
      ARGS+=("--include" "/opt/bitnami/redis/etc/master.conf")
      exec redis-server "${ARGS[@]}"
  kind: ConfigMap
  metadata:
    labels:
      app.kubernetes.io/instance: assisted-events-streams
      app.kubernetes.io/name: redis
    name: assisted-events-streams-redis-scripts
- apiVersion: v1
  data:
    ping_liveness_local.sh: |-
      #!/bin/bash

      [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
      [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
      response=$(
        timeout -s 3 $1 \
        redis-cli \
          -h localhost \
          -p $REDIS_PORT \
          ping
      )
      if [ "$?" -eq "124" ]; then
        echo "Timed out"
        exit 1
      fi
      responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
      if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ] && [ "$responseFirstWord" != "MASTERDOWN" ]; then
        echo "$response"
        exit 1
      fi
    ping_liveness_local_and_master.sh: |-
      script_dir="$(dirname "$0")"
      exit_status=0
      "$script_dir/ping_liveness_local.sh" $1 || exit_status=$?
      "$script_dir/ping_liveness_master.sh" $1 || exit_status=$?
      exit $exit_status
    ping_liveness_master.sh: |-
      #!/bin/bash

      [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
      [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
      response=$(
        timeout -s 3 $1 \
        redis-cli \
          -h $REDIS_MASTER_HOST \
          -p $REDIS_MASTER_PORT_NUMBER \
          ping
      )
      if [ "$?" -eq "124" ]; then
        echo "Timed out"
        exit 1
      fi
      responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
      if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ]; then
        echo "$response"
        exit 1
      fi
    ping_readiness_local.sh: |-
      #!/bin/bash

      [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
      [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
      response=$(
        timeout -s 3 $1 \
        redis-cli \
          -h localhost \
          -p $REDIS_PORT \
          ping
      )
      if [ "$?" -eq "124" ]; then
        echo "Timed out"
        exit 1
      fi
      if [ "$response" != "PONG" ]; then
        echo "$response"
        exit 1
      fi
    ping_readiness_local_and_master.sh: |-
      script_dir="$(dirname "$0")"
      exit_status=0
      "$script_dir/ping_readiness_local.sh" $1 || exit_status=$?
      "$script_dir/ping_readiness_master.sh" $1 || exit_status=$?
      exit $exit_status
    ping_readiness_master.sh: |-
      #!/bin/bash

      [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
      [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
      response=$(
        timeout -s 3 $1 \
        redis-cli \
          -h $REDIS_MASTER_HOST \
          -p $REDIS_MASTER_PORT_NUMBER \
          ping
      )
      if [ "$?" -eq "124" ]; then
        echo "Timed out"
        exit 1
      fi
      if [ "$response" != "PONG" ]; then
        echo "$response"
        exit 1
      fi
  kind: ConfigMap
  metadata:
    labels:
      app.kubernetes.io/instance: assisted-events-streams
      app.kubernetes.io/name: redis
    name: assisted-events-streams-redis-health
- apiVersion: v1
  data:
    master.conf: |-
      dir /data
      # User-supplied master configuration:
      rename-command FLUSHDB ""
      rename-command FLUSHALL ""
      # End of master configuration
    redis.conf: |-
      # User-supplied common configuration:
      # Enable AOF https://redis.io/topics/persistence#append-only-file
      appendonly yes
      # Disable RDB persistence, AOF persistence already enabled.
      save ""
      # End of common configuration
    replica.conf: |-
      dir /data
      slave-read-only yes
      # User-supplied replica configuration:
      rename-command FLUSHDB ""
      rename-command FLUSHALL ""
      # End of replica configuration
  kind: ConfigMap
  metadata:
    labels:
      app.kubernetes.io/instance: assisted-events-streams
      app.kubernetes.io/name: redis
    name: assisted-events-streams-redis-configuration
- apiVersion: v1
  data:
    zookeeper.config: |-
      zookeeper.ssl.client.enable=true
      zookeeper.ssl.protocol=TLSv1.2
      zookeeper.clientCnxnSocket=org.apache.zookeeper.ClientCnxnSocketNetty
  kind: ConfigMap
  metadata:
    name: enriched-event-projection-zookeeper-client-config
- apiVersion: v1
  data:
    setup_acls: |-
      export ZOOKEEPER=$(echo ${ZOOKEEPER_CONNECT_STRING} | cut -d, -f1)
      ZK_TLS=""
      if [ "${ZOOKEEPER_TLS}" == "true" ]; then
        ZK_TLS="--zk-tls-config-file /opt/zookeeper/zookeeper.config"
      fi
      # setup admin user
      /opt/kafka/bin/kafka-acls.sh --authorizer-properties zookeeper.connect=${ZOOKEEPER} --add --allow-principal "User:${ADMIN_USERNAME}" ${ZK_TLS} --operation Create --cluster

      # setup read user
      /opt/kafka/bin/kafka-acls.sh --authorizer-properties zookeeper.connect=${ZOOKEEPER} --add --allow-principal "User:${READ_USERNAME}" --operation Read --group "${KAFKA_GROUP_ID}" --topic "${KAFKA_TOPIC}" ${ZK_TLS}
      # setup write user
      /opt/kafka/bin/kafka-acls.sh --authorizer-properties zookeeper.connect=${ZOOKEEPER} --add --allow-principal "User:${WRITE_USERNAME}" --operation Write --topic "${KAFKA_TOPIC}" ${ZK_TLS}
    setup_topics: |
      echo "sasl.mechanism=SCRAM-SHA-512
      security.protocol=SASL_SSL
      sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \\
           username=\"${ADMIN_USERNAME}\" \\
           password=\"${ADMIN_PASSWORD}\";" > /tmp/admin-scram.properties

      /opt/kafka/bin/kafka-topics.sh --bootstrap-server ${BOOTSTRAP_SERVERS} --command-config /tmp/admin-scram.properties --topic "${KAFKA_TOPIC}" --create --if-not-exists --partitions ${KAFKA_TOPIC_PARTITIONS} --replication-factor ${KAFKA_TOPIC_REPLICATION_FACTOR} --config retention.ms=${KAFKA_TOPIC_RETENTION_MS}
  kind: ConfigMap
  metadata:
    name: enriched-event-projection-kafka-setup
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: enriched-event-projection
  spec:
    replicas: ${{REPLICAS_COUNT}}
    selector:
      matchLabels:
        app.kubernetes.io/name: enriched-event-projection
    template:
      metadata:
        labels:
          app.kubernetes.io/name: enriched-event-projection
      spec:
        containers:
        - command:
          - /projection
          env:
          - name: OPENSEARCH_CONFIG_INDEX
            value: ${OPENSEARCH_CONFIG_INDEX}
          - name: OPENSEARCH_BULK_WORKERS
            value: ${OPENSEARCH_BULK_WORKERS}
          - name: OPENSEARCH_BULK_FLUSH_BYTES
            value: ${OPENSEARCH_BULK_FLUSH_BYTES}
          - name: OPENSEARCH_BULK_FLUSH_INTERVAL
            value: ${OPENSEARCH_BULK_FLUSH_INTERVAL}
          - name: OPENSEARCH_RESPONSE_TIMEOUT
            value: ${OPENSEARCH_RESPONSE_TIMEOUT}
          - name: OPENSEARCH_SSL_INSECURE_SKIP_VERIFY
            value: ${OPENSEARCH_SSL_INSECURE_SKIP_VERIFY}
          - name: KAFKA_EVENT_STREAM_TOPIC
            value: ${KAFKA_EVENT_STREAM_TOPIC}
          - name: LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: KAFKA_GROUP_ID
            value: ${KAFKA_GROUP_ID}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - name: KAFKA_BOOTSTRAP_SERVER
            valueFrom:
              secretKeyRef:
                key: ${BOOTSTRAP_BROKERS_SECRET_KEY}
                name: ${BOOTSTRAP_BROKERS_SECRET_NAME}
          - name: KAFKA_CLIENT_ID
            valueFrom:
              secretKeyRef:
                key: ${KAFKA_CREDENTIALS_USERNAME_KEY}
                name: ${KAFKA_CREDENTIALS_SECRETNAME}
          - name: KAFKA_CLIENT_SECRET
            valueFrom:
              secretKeyRef:
                key: ${KAFKA_CREDENTIALS_PASSWORD_KEY}
                name: ${KAFKA_CREDENTIALS_SECRETNAME}
          - name: REDIS_ADDRESS
            value: ${REDIS_ADDRESS}
          - name: REDIS_PASSWORD
            valueFrom:
              secretKeyRef:
                key: password
                name: ${REDIS_CREDENTIALS_SECRETNAME}
          - name: OPENSEARCH_INDEX_PREFIX
            value: ${OPENSEARCH_INDEX_PREFIX}
          - name: OPENSEARCH_ADDRESS
            valueFrom:
              secretKeyRef:
                key: endpoint
                name: ${OPENSEARCH_ENDPOINT_SECRETNAME}
          - name: OPENSEARCH_USERNAME
            valueFrom:
              secretKeyRef:
                key: master_user_name
                name: ${OPENSEARCH_CREDENTIALS_SECRETNAME}
          - name: OPENSEARCH_PASSWORD
            valueFrom:
              secretKeyRef:
                key: master_user_password
                name: ${OPENSEARCH_CREDENTIALS_SECRETNAME}
          image: ${IMAGE_NAME}:${IMAGE_TAG}
          imagePullPolicy: ${IMAGE_PULL_POLICY}
          name: projection
          resources:
            limits:
              cpu: ${CPU_LIMIT}
              memory: ${MEMORY_LIMIT}
            requests:
              cpu: ${CPU_REQUEST}
              memory: ${MEMORY_REQUEST}
        initContainers:
        - command:
          - bash
          - -c
          - /opt/scripts/setup_acls && /opt/scripts/setup_topics
          env:
          - name: KAFKA_HEAP_OPTS
            value: ${KAFkA_HEAP_OPTS}
          - name: KAFKA_TOPIC
            value: ${KAFKA_EVENT_STREAM_TOPIC}
          - name: KAFKA_TOPIC_PARTITIONS
            value: ${KAFKA_TOPIC_PARTITIONS}
          - name: KAFKA_TOPIC_REPLICATION_FACTOR
            value: ${KAFKA_TOPIC_REPLICATION_FACTOR}
          - name: KAFKA_TOPIC_RETENTION_MS
            value: "2419200000"
          - name: ADMIN_USERNAME
            valueFrom:
              secretKeyRef:
                key: ${ADMIN_USERNAME_SECRET_KEY}
                name: ${ADMIN_USERNAME_SECRET_NAME}
          - name: ADMIN_PASSWORD
            valueFrom:
              secretKeyRef:
                key: ${ADMIN_PASSWORD_SECRET_KEY}
                name: ${ADMIN_PASSWORD_SECRET_NAME}
          - name: READ_USERNAME
            valueFrom:
              secretKeyRef:
                key: ${READ_USERNAME_SECRET_KEY}
                name: ${READ_USERNAME_SECRET_NAME}
          - name: WRITE_USERNAME
            valueFrom:
              secretKeyRef:
                key: ${WRITE_USERNAME_SECRET_KEY}
                name: ${WRITE_USERNAME_SECRET_NAME}
          - name: ZOOKEEPER_TLS
            value: ${ZOOKEEPER_TLS}
          - name: ZOOKEEPER_CONNECT_STRING
            valueFrom:
              secretKeyRef:
                key: ${ZOOKEEPER_CONNECT_STRING_SECRET_KEY}
                name: ${ZOOKEEPER_CONNECT_STRING_SECRET_NAME}
          - name: BOOTSTRAP_SERVERS
            valueFrom:
              secretKeyRef:
                key: ${BOOTSTRAP_BROKERS_SECRET_KEY}
                name: ${BOOTSTRAP_BROKERS_SECRET_NAME}
          image: ${KAFKA_IMAGE_NAME}:${KAFKA_IMAGE_TAG}
          name: kafka-client
          resources:
            limits:
              cpu: ${INIT_KAFKA_CPU_LIMIT}
              memory: ${INIT_KAFKA_MEMORY_LIMIT}
            requests:
              cpu: ${INIT_KAFKA_CPU_REQUEST}
              memory: ${INIT_KAFKA_MEMORY_REQUEST}
          volumeMounts:
          - mountPath: /opt/scripts
            name: scripts
          - mountPath: /opt/zookeeper/zookeeper.config
            name: zookeeper-config
            subPath: zookeeper.config
        volumes:
        - configMap:
            defaultMode: 493
            name: enriched-event-projection-kafka-setup
          name: scripts
        - configMap:
            defaultMode: 484
            name: enriched-event-projection-zookeeper-client-config
          name: zookeeper-config
parameters:
- name: REDIS_EXPORTER_IMAGE_TAG
  value: 1.37.0-debian-10-r63
- name: REDIS_EXPORTER_IMAGE_NAME
  value: quay.io/edge-infrastructure/redis-exporter
- name: REDIS_IMAGE_TAG
  value: 6.2.7-debian-10-r23
- name: REDIS_IMAGE_NAME
  value: quay.io/edge-infrastructure/redis
- name: REDIS_STORAGE
  value: 100Gi
- name: IMAGE_PULL_POLICY
  value: Always
- name: REPLICAS_COUNT
  value: "1"
- name: IMAGE_NAME
  value: quay.io/edge-infrastructure/assisted-events-stream
- name: IMAGE_TAG
  required: true
  value: ""
- name: KAFKA_IMAGE_NAME
  value: quay.io/strimzi/kafka
- name: KAFKA_IMAGE_TAG
  value: 0.27.1-kafka-2.8.1
- name: CPU_LIMIT
  value: "1"
- name: CPU_REQUEST
  value: 10m
- name: MEMORY_LIMIT
  value: 512Mi
- name: MEMORY_REQUEST
  value: 256Mi
- name: INIT_KAFKA_CPU_LIMIT
  value: "1"
- name: INIT_KAFKA_CPU_REQUEST
  value: 10m
- name: INIT_KAFKA_MEMORY_LIMIT
  value: 2048Mi
- name: INIT_KAFKA_MEMORY_REQUEST
  value: 1024Mi
- name: KAFKA_HEAP_OPTS
  value: -Xms512m -Xmx1g
- name: NAMESPACE
  value: assisted-events-streams
- name: KAFKA_TOPIC_PARTITIONS
  value: "1"
- name: KAFKA_TOPIC_REPLICATION_FACTOR
  value: "1"
- name: KAFKA_TOPIC_RETENTION_MS
  value: "2419200000"
- name: KAFKA_EVENT_STREAM_TOPIC
  value: events-stream-integration
- name: KAFKA_GROUP_ID
  value: enriched-event-projection
- name: REDIS_ADDRESS
  value: assisted-events-streams-redis:6379
- name: REDIS_CREDENTIALS_SECRETNAME
  value: redis-credentials
- name: OPENSEARCH_CREDENTIALS_SECRETNAME
  value: elastic-master-credentials
- name: OPENSEARCH_ENDPOINT_SECRETNAME
  value: assisted-installer-elasticsearch
- name: OPENSEARCH_INDEX_PREFIX
  value: assisted-installer-events-v1-
- name: OPENSEARCH_CONFIG_INDEX
  value: config
- name: OPENSEARCH_BULK_WORKERS
  value: "1"
- name: OPENSEARCH_BULK_FLUSH_BYTES
  value: "10000000"
- name: OPENSEARCH_BULK_FLUSH_INTERVAL
  value: 120s
- name: OPENSEARCH_RESPONSE_TIMEOUT
  value: 90s
- name: OPENSEARCH_SSL_INSECURE_SKIP_VERIFY
  value: "true"
- name: KAFKA_CREDENTIALS_SECRETNAME
  value: kafka-dummy-user
- name: KAFKA_CREDENTIALS_USERNAME_KEY
  value: username
- name: KAFKA_CREDENTIALS_PASSWORD_KEY
  value: password
- name: KAFKA_SASL_MECHANISM
  value: PLAIN
- name: LOG_LEVEL
  value: info
- name: ZOOKEEPER_TLS
  value: "false"
- name: ZOOKEEPER_CONNECT_STRING_SECRET_KEY
  value: zookeeper_connect_string
- name: ZOOKEEPER_CONNECT_STRING_SECRET_NAME
  value: kafka
- name: BOOTSTRAP_BROKERS_SECRET_KEY
  value: bootstrap_brokers
- name: BOOTSTRAP_BROKERS_SECRET_NAME
  value: kafka
- name: ADMIN_USERNAME_SECRET_KEY
  value: username
- name: ADMIN_USERNAME_SECRET_NAME
  value: kafka-admin-user
- name: ADMIN_PASSWORD_SECRET_KEY
  value: password
- name: ADMIN_PASSWORD_SECRET_NAME
  value: kafka-admin-user
- name: READ_USERNAME_SECRET_KEY
  value: username
- name: READ_USERNAME_SECRET_NAME
  value: kafka-read-user
- name: WRITE_USERNAME_SECRET_KEY
  value: username
- name: WRITE_USERNAME_SECRET_NAME
  value: kafka-write-user
